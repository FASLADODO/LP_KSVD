-----------------------------------------------------------------------------------------------
----------------------------
Copyright(c) 2014 Weiyang Liu.
All Rights Reserved.
-----------------------------------------------------------------------------------------------
----------------------------
Permission to use, copy, or modify this software and its documentation for educational
and research purposes only and without fee is here granted, provided that this copyright
notice and the original authors' names appear on all copies and supporting documentation.
This program shall not be used, rewritten, or adapted as the basis of a commercial
software or hardware product without first obtaining permission of the authors. The
authors make no representations about the suitability of this software for any purpose.
It is provided "as is" without express or implied warranty.
-----------------------------------------------------------------------------------------------
----------------------------
About the demos
1. To run the example code: 
(a) add the toolbox paths 'ksvdbox' and 'OMPbox' into the matlab path;

  addpath(genpath('.\OMPbox'));
  addpath(genpath('.\ksvdbox'));

* Please note that you might need to recompile these two toolboxes once you use Linux or Mac OS.
You can simply run these two files in matlab:
./OMPbox/private/make.m
./ksvdbox/private/make.m

(b) run main.m

The mat file 'featurevector' in the folder 'trainingdata' is one random split of training data and testing data 
on the Extended YaleB dataset. The final recognition accuracy of this example should be (after 10 outer iterations):

  Final recognition rate for LP-KSVD is : 0.985

2. About the model parameters

The model parameters is very crucial for the LP-KSVD algorithm. These parameters
should be different for different datasets. They should be adjusted to the optimal
values via cross validation. Note that, the current parameters settings are designed
for the kernel LP-KSVD with 1216 dictionary size and extended YaleB face dataset.
Any changes of the parameters may be detrimental to the performance.

3. About the outer iteration number

The outer iteration number should be large enough to learn a proper locality preserving
matrix. In our code, we set it to 10. Note that, LP-KSVD is relatively time-consuming.
In a 3.4GHz Dual-core PC with 16GB RAM, we train LP-KSVD algorithm and run the testing in
about 1 hour.
-----------------------------------------------------------------------------------------------
----------------------------
When using the code in your research work, you should cite the following paper:

Joint Kernel Dictionary and Classifier Learning for Sparse Coding via Locality Preserving K-SVD,
Weiyang Liu, Zhiding Yu, Meng Yang, Lijia Lu, and Yuexian Zou,
International Conference on Multimedia & Expo (ICME), 2015.

Paper can be found at https://sites.google.com/site/weiyangliu92/

-----------------------------------------------------------------------------------------------
----------------------------
This is for research purpose only.
You can replace the dataset with your own dataset for further experiments.
For any problem about the code, please contact to {wyliu@pku.edu.cn}

Written by Weiyang Liu, (B.Eng. in South China Univ. of Tech., M.S. Candidate in Peking Univ.)
Email: wyliu@pku.edu.cn, eulerliu@gmail.com
Homepage: https://sites.google.com/site/weiyangliu92/


